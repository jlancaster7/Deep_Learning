import numpy as np
import torch
import torch.nn.functional as F
from torchvision import datasets, transforms
from tqdm.notebook import tqdm

mnist_train = datasets.MNIST(root="./datasets", train=True, transform=transforms.ToTensor(), download=True)
mnist_test = datasets.MNIST(root="./datasets", train=False, transform=transforms.ToTensor(), download=True)
train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=500, shuffle=True)
test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)

## Training
# Initialize parameters
W = torch.randn(784, 500)/np.sqrt(784)
W.requires_grad_()
b = torch.zeros(500, requires_grad=True)

W_h = torch.randn(500, 10)/np.sqrt(500)
W_h.requires_grad_()
b_h = torch.zeros(10, requires_grad=True)


# Optimizer
optimizer = torch.optim.SGD([W,b,W_h,b_h], lr=0.1)

for i in range(10):
    train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)
    for images, labels in tqdm(train_loader):
        optimizer.zero_grad()
        
        # Forward pass
        x = images.view(-1, 28*28)
        y = torch.matmul(x, W) + b
        y = F.relu(y)
        z = torch.matmul(y, W_h) + b_h

        cross_entropy = F.cross_entropy(z, labels)
        # Backward pass
        cross_entropy.backward()
        optimizer.step()

## Testing
correct = 0
total = len(mnist_test)

with torch.no_grad():

    for images, labels in tqdm(test_loader):
        # Forward pass
        x = images.view(-1, 28*28)
        y = torch.matmul(x, W) + b
        z = torch.matmul(y, W_h) + b_h
        
        predictions = torch.argmax(z, dim=1)
        correct += torch.sum((predictions == labels).float())
    
print('Test accuracy: {}'.format(correct/total))


